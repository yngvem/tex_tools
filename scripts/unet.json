{
	"neural_net.png": "f(x; W) = \\fbreve_n(\\fbreve_{n-1}( ... \\fbreve_2( \\fbreve_1 (x; W_1), W_2) ..., W_{n-1}), W_n)",
	"training_set.png": "\\mathcal{T} = \\left\\{ \\left(x^{(i)}, y^{(i)}\\right) \\right\\}_{i}",
	"layer.png": "\\fbreve_k(x; A, b) = \\phi(Ax + b)",
	"relu.png": "\\phi(x) = \\max(x, 0)",
	"leaky_relu.png": "\\phi_a(x) = \\max(x, ax)",
	"machine_learning1.png": "f(x) \\approx y",
	"machine_learning2.png": "f(x; W) \\approx y",
	"loss.png": "L(W; \\mathcal{T}) = \\sum_{(x^{(i)}, y^{(i)}) \\in \\mathcal{T}} l(f(x^{(i)}; W), y^{(i)})",
	"cross_entropy.png": "l_{\\text{CE}}(f(x^{(i)}; W), y^{(i)}) = -\\sum_p \\left[ y_p^{(i)} log\\left(f\\left(x_p^{(i)}\\right)\\right) + \\left(1 - y_p^{(i)}\\right) log\\left(1 - f\\left(x_p^{(i)}\\right)\\right)\\right]",
	"dice.png": "l_{\\text{dice}}(f(x^{(i)}; W), y^{(i)}) = \\frac{2 \\sum_p \\left[ f(x_p^{(i)}; W) y_p^{(i)} \\right]}{\\sum_p f(x_p^{(i)}; W) + \\sum_p y_p^{(i)}}"
}
